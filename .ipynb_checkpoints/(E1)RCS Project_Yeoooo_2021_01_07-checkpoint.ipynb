{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/rock_scissor_paper/scissor\"\n",
    "#이미지 디렉토리에 타겟 파일의 경로를 저장\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "#glob은 파일들의 리스트를 뽑을 때 사용하며 파일의 경로명을 이용해서 원하는대로 조작 가능\n",
    "#glob을 통하여 image_dir_path에 저장된 변수의 jpg 파일들을 선택\n",
    "\n",
    "target_size=(100,100)\n",
    "#target_size 변수에 28, 28 배열을 저장 \n",
    "\n",
    "for img in images:\n",
    "    #모든 이미지를 탐색하며\n",
    "    old_img=Image.open(img)\n",
    "    #old_img 변수에 타겟 이미지를 저장\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    #new_img 변수에 target_size의 값으로 resize\n",
    "    \n",
    "    new_img.save(img,\"JPEG\")\n",
    "    #resize된 new_img를 JPEG 확장자로 저장\n",
    "\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"*바위* , *보* \"  또한 같은 방식으로 resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이어서 이미지파일을 불러내기 위해 load_file 함수를 정의 해준다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 원하는 사이즈로 resize를 했다면 이제는 \n",
    "_본격적인 데이터 전처리_ 를 해야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1800 입니다.\n",
      "x_train shape: (1800, 28, 28, 3)\n",
      "y_train shape: (1800,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=1800   # 데이터의 총합의 개수를 맞춰줘야 한다!\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨데이터를 담을 행렬(matrix) 영역을 생성한다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    #이 때 행렬 계산을 할 수 있게 도와주는 라이브러리인 위에서np로 예약어 설정을 한 numpy\n",
    "    #라이브러리를 사용한다!\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사해준다.\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    #데이터의 수는 이미지행렬을 복사한 수만큼 늘어난 idx로 파악한다\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력된 데이터는 0~255의 범위만큼 난잡하게 표현될 필요없다!\n",
    "#따라서 255로 나눠 정규화를 진행한 값을 저장해둔다.\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))#실제 이미지 데이터가 들어가 있는 x_train\n",
    "print(\"y_train shape: {}\".format(y_train.shape))#이미지에 대한 라벨이 들어가있는 y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터들이 학습데이터들로 잘 만들어졌는지 파악한다.  \n",
    "x_train 의 shape는 28x28사이즈에 R, G, B 3채널로 이뤄져있는 1800개의 데이터로 이뤄져있다.</br>\n",
    "y_train 의 shape는 라벨이기 때문에 1800개의 라벨로 구성되어있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이제는 정말 데이터가 들어가있는지 눈으로 확인할 차례!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #강력한 시각화 기능을 제공하는 matplotlib 라이브러리 모듈\n",
    "plt.imshow(x_train[0]) #xtrain에 들어있는 첫번재 이미지를 imshow메서드를 통해 불러온다\n",
    "print('라벨: ', y_train[0])#동시에 라벨도.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습시키기 전에...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                204864    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 281,162\n",
      "Trainable params: 281,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model에 추가된 Layer 개수:  7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#하이퍼파라미터들\n",
    "n_channel_1=64 #얼마나 많은 특징을 보는가\n",
    "n_channel_2=128 #얼마나 많은 특징을 보는가\n",
    "n_dense= 64 #분류기 알고리즘을 얼마나 복잡하게 할 것인가 / 복잡한 이미지일수록 높여주면 좋음\n",
    "n_train_epoch=15 #훈련 횟수(...?)\n",
    "\n",
    "model=keras.models.Sequential()#keras라이브러리의 모델중 간단히 모델을 만들어낼 수 있는 \n",
    "                                #Sequential 모델을 이용할 것이다.\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3))\n",
    "          #Conv2D는 필터로 특징을 뽑아주는 Convoultion(합성곱)레이어이다 \n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "          #MaxPool2D는 여러 종류의 Pooling Layer중에서 이미지 분류 모델에 가장 많이\n",
    "          #활용된다고 한다. 그 이유는...나중에 알아보자\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "          #다차원 배열을 Flatten 메서드를 통해서 1차원으로 바꿔줄 수 있다!\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "          #Dense는 입력뉴런과 출력 뉴런을 연결해준다. 이를 전결합층이라고 한다 \n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "        #두 번 쓰인 이유는 뭘까?\n",
    "\n",
    "model.summary()\n",
    "          #summary는 모델 구조 파악을 직관적으로 표현한다\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 데이터 처리를 해줄 모델을 만들어줘야한다.  \n",
    "모델에는 각 층을 추가해서 구성해줘야 한다.(레고 블럭 같달까..)  \n",
    "\n",
    "이곳에서 설명하기 위해 주석에서는 아껴뒀는데, 두 레이어에 대해 간략하게 짚어봐야겠다  \n",
    "* __컨벌루션 레이어(합성곱 레이어)__  \n",
    "  \n",
    "  첫번째 인자는 컨벌루션 필터의 수가 들어가며 \n",
    "    \n",
    "  두번째 인자는  컨벌루션 커널의(행, 열)이 들어간다. \n",
    "    \n",
    "  세번째 인자로는 padding이 들어갈 수 있는데 이는 선택적인 것 같다.  \n",
    "   padding은 경계에 대한 처리 방법을 정의하는 곳인데, 아직까지는 깊게 파고들지 않을 것이다.\n",
    "     \n",
    "  네번째 인자로는 activation 으로 활성화 함수를 설정하는 곳이다.  \n",
    "   이곳에는 linear, relu, sigmoid, softmax가 들어갈 수 있다고 한다.  \n",
    "     \n",
    "\n",
    "* __Pooling 레이어__\n",
    "  \n",
    "  더 높은 정확도를 위해서는 필터가 많아야한다.  \n",
    "  필터가 늘어나는 것은 곧 차원이 늘어나는 것인데, 차원이 늘어난다면 오버피팅 문제와  \n",
    "  이런저런 문제들에 영향을 끼친다고 한다.  \n",
    "  이런 문제를 해결하기 위해서 차원을 감소시키는 역할을 하는것이 Pooling Layer라고 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "#compile은 모델을 학습시키기 위한 학습과정을 설정하는 단계! \n",
    "#optimizer는 훈련 과정을 설정한다. 그 중 adam은 최적화하는 방향으로 학습이 일어난다고 한다.\n",
    "#mertics는 훈련과정을 모니터링 하는 방식을 설정할 수 있다! accuracy로 설정시에 학습과정에서 정확도를 수집한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 드디어 학습!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0400 - accuracy: 0.9842\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0099 - accuracy: 0.9989\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0243 - accuracy: 0.9920\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0523 - accuracy: 0.9837\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 0.9980\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.6319e-04 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.6521e-04 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.9225e-04 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5165e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9ccff41150>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_reshaped, y_train, epochs=15)\n",
    "#x_train_reshaped, y_train을 사용하여 학습한다\n",
    "#epochs는 전체 입력데이터를 몇번 순회하는가를 지정해줄 수 있다 (몇 번 학습할 것인가로 이해해도 될 듯 싶다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 완료!\n",
    "\n",
    "이제 제대로 학습했는지 테스트를 해야할 시간이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터(x_test)의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300  #테스트 데이터의 개수에 유의해야한다!\n",
    "    img_size=28\n",
    "    color=3\n",
    "    \n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/testset/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img   \n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/testset/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/testset/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트 데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "#이미지 데이터를 불러올 수 있게 train 데이터를 만드는 방식과 똑 같 다\n",
    "  \n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이제 마지막으로 테스트 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.7473 - accuracy: 0.7133\n",
      "test_loss: 0.7473486661911011 \n",
      "test_accuracy: 0.7133333086967468\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "#손실률과 정확도를 model.evaluate로 측정한다\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 결과는 정확도 0.7을 웃도는 결과가 나오는 가위바위보 이미지 분류기가 완성되었다!  \n",
    "살짝 아쉬운 결과이지만 내가 더 이상 버틸수가 없었다..  \n",
    "\n",
    "이번 프로젝트에서 가장 어려웠던 점은 데이터였다.\n",
    "처음 시도할 때는 정확도가 0.33333으로만 나오는데다가 이미지 손상문제가 있어서  \n",
    "많은 혼란이 있었지만, 데이터를 아예 갈아 엎어버리고 테스트셋까지 새로 갈아주니  \n",
    "언제 그랬냐는듯 잘만 돌아갔었다..  \n",
    "  \n",
    "여전히 이름도모르는 라이브러리와 메서드들에 혼란을 겪고있다.  \n",
    "처음 자바를 배웠을 때 처럼 의미도 모르고 계속계속 사용하고 찾아보다보면 어느새에 내게 녹아있지 않을까 하는 생각이 들었다!\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
