{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn_ 5개의 분류 모델\n",
    "- Decision Tree Classifier  \n",
    "    이진트리의 형태를 가진다  \n",
    "    __한번에 하나씩의 설명변수를 사용, 예측 가능한 규칙들의 집합을 생성한다!__  \n",
    "    분류와 회귀 모두 가능하다(=범주나 연속형 수치 모두 예측가능하다)  \n",
    "    계산 복잡성 대비 높은 예측 성능을 낼 수 있다.  \n",
    "    변수 단위로 설명할 수 있다는 강점이 있다.  \n",
    "    __결정 경계가 데이터 축에 수직인 형태이므로 특정 데이터에만 잘 작동할 가능성이 높다!__\n",
    "      \n",
    "      \n",
    "-  __Random Forest Classifier__  \n",
    "\n",
    "     __같은 데이터에 의사결정 트리를 여러개 적용하여 성능을 높이는 Ensemble(앙상블) 기법__   \n",
    "여러개의 의사 결정 트리이기때문에 역시 분류, 회귀 모두 적용 가능한 모델이다  \n",
    "__의사결정 트리의 단점을 보완한 모델!__  \n",
    "random의 의미는 각각 의사결정 트리를 만들기 위해 쓰이는 _특성들을 랜덤으로_ 선택한다  \n",
    "\n",
    "    \n",
    "- __SVM(Support Vector Machine)__ \n",
    "  \n",
    "    학습 데이터를 비선형 Mapping을 통해 고차원으로 변환한다. 만들어진 새로운 차원에서  \n",
    "    초평면을 최적으로 분리하는 선형분리를 찾는 모델이다(= 최적의 의사결정 경계를 찾는다)  \n",
    "        \n",
    "        \n",
    "- __SGD(Stochastic Gradient Descent) Classifier__    \n",
    "\n",
    "    보통의 Gradient Descent(경사 하강법)에서 전체 데이터(Batch)가 아니라  \n",
    "    일부 데이터의 모음을 사용하는 방법이다.  \n",
    "    Mini-Batch를 사용하기 때문에 정확도는 낮아지나 계산속도가 빠르다!\n",
    "      \n",
    "  \n",
    "- __Logistic Regression__  \n",
    "  \n",
    "  __회귀를 사용하여 데이터가 특정 범주에 속할 확률을 0~1사이 값으로 예측하고 예측 확률에  \n",
    "  따라 더 높은 확률을 가진 범주에 속하는 것으로 분류하는 알고리즘이다__  \n",
    "    \n",
    "    \n",
    "사실 더 어려운 이야기가 많았지만, 함축적으로 적어보았다.  \n",
    "아이펠에서 알려줄것이다.. 꼭 그렇게 생각한다..\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits() #데이터 불러오기\n",
    "digits_data = digits.data #digits_data에 실제 digits의 데이터를 넣어준다\n",
    "digits_label = digits.target #digits_label에 실제 digits의 라벨을 넣어준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names \n",
    "#digit의 레이블 이름들이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        4.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        1.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        2.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        8.0        0.0   \n",
       "\n",
       "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0           0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1           0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2           0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3           0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4           0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        2.0       14.0       15.0        9.0   \n",
       "1793        0.0        0.0        6.0       16.0       14.0        6.0   \n",
       "1794        0.0        0.0        2.0        9.0       13.0        6.0   \n",
       "1795        0.0        0.0        5.0       12.0       16.0       12.0   \n",
       "1796        0.0        1.0        8.0       12.0       14.0       12.0   \n",
       "\n",
       "      pixel_7_6  pixel_7_7  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           9.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "...         ...        ...  \n",
       "1792        0.0        0.0  \n",
       "1793        0.0        0.0  \n",
       "1794        0.0        0.0  \n",
       "1795        0.0        0.0  \n",
       "1796        1.0        0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_df = pd.DataFrame(data=digits_data, columns=digits.feature_names)\n",
    "\n",
    "digits_df\n",
    "#pandas로 어떤 데이터들이 들어있는지 묘사하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수우우많은 데이터들 중에서 train data와 test data를 나누어 줘야한다.   \n",
    "이는 아래와 같이 train_test_split 함수로 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = digits_data\n",
    "label = digits_label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, #쓸 데이터(== feature)\n",
    "                                                    label, #쓸 라벨(==target,==label)\n",
    "                                                    test_size=0.2, #전체 데이터 중 '20%'를 test set에 사용하겠다!\n",
    "                                                    random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류하는 방식이 다른 5가지 모델에서 성능이 어떻게 다를지 궁금했다.  \n",
    "따라서 모든 모델을 만들어서 구동시켜 보았다.\n",
    "\n",
    "# 그전에!  \n",
    "평가지표를 먼저 지정해주어야한다. 즉, 어떤 값을 모델의 산출물로 낼 것인가를 설정하는 것이다.  \n",
    "일단 평가지표에 대해 먼저 알아보려고 한다.  \n",
    "평가지표는 Precision(정밀도), Recall(재현율), F1-Score, Accuracy로 4가지이다.  \n",
    "- __Precision__  \n",
    "    분류기가 참으로 분류한 결과 중에서 실제 참의 비율이다  \n",
    "    TP/TP+FP로 Positive에 의해 결정된다. precision의 경우에 함정이 있다. \n",
    "    스팸메일 분류기의 경우 스팸메일을 스팸으로 예측한다면 정밀도는 100%가 될 것이다.\n",
    "    (스팸메일에서 정상메일을 걸러주거나, 정상메일에서 스팸을 걸러줘야하는데 말이다!)\n",
    "  \n",
    "  \n",
    "- __Recall__  \n",
    "    실제 참 중에서 분류기가 참으로 분류한 비율이다  \n",
    "    TP/TP+TN로 결정된다    \n",
    "    precision과 같이 함정을 가지고 있다 !\n",
    "    암환자를 예측하는 분류기를 예시로 들었을 때, 모든 사람을 양성으로, 암환자로 표시한다면 \n",
    "    맞춰야하는 양성환자는 모두 맞추었기 때문에, Recall을 100%으로 만들어줄 수 있다!\n",
    "      \n",
    " ------------------------------------------------------------------------------------\n",
    "     재현율(Recall)와 정밀도(Precision)은 데이터에 따라 중요도가 달라질 수 있다.  \n",
    "     재현율이 더 중요한 경우는 Positive를 Negative로 판단하면 업무상에 큰 영향이 있는\n",
    "     경우 이며, 정밀도가 더 중요한 경우는 Negatvie데이터를 Positive로 판단하면 업무상  \n",
    "     영향을 줄 수 있는 경우이다.    \n",
    "     \n",
    " ---------------------------------------------------------------------------------\n",
    "  \n",
    "- __F1-Score__  \n",
    "    Precision과 Recall의 조화평균으로, 분류 클래스 간에 데이터가 심각하게 불균형을  \n",
    "    이루는 경우에 사용된다.  \n",
    "    \n",
    "    \n",
    "- __Accuracy__  \n",
    "    True를 True로 예측하고 또한 False를 False로 예측한 경우이다  \n",
    "    TP+TN/TP+FN+FP+TN 으로 결정된다\n",
    "    Accuracy 같은 경우에도 함정이 있다. 만약 어떤 학교에서 90명의 남학생과 10명의  \n",
    "    여학생이 있는 경우, 분류기는 모두를 남학생으로 판단해도 정확도는 90%가 될 것이다!  \n",
    "    (불균형 데이터의 경우 정확도를 뽑아내기 힘들다)\n",
    "    \n",
    "위에 언급한 지표들 말고도, Confusion Matrix(혼합 행렬), Precision-Recall그래프,  \n",
    "Average Precision, ROC/AUC가 있었지만, 차후에 알아볼 것이다.\n",
    "    \n",
    "\n",
    "### 아래는 위에서 언급했던 분류 모델중  Decision Tree Classifier 이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        37\n",
      "           1       0.91      0.91      0.91        34\n",
      "           2       0.81      0.88      0.85        34\n",
      "           3       0.79      0.85      0.82        40\n",
      "           4       0.73      0.79      0.76        34\n",
      "           5       0.91      0.91      0.91        32\n",
      "           6       0.94      0.92      0.93        37\n",
      "           7       0.95      0.88      0.91        40\n",
      "           8       0.74      0.70      0.72        33\n",
      "           9       0.81      0.77      0.79        39\n",
      "\n",
      "    accuracy                           0.85       360\n",
      "   macro avg       0.85      0.85      0.85       360\n",
      "weighted avg       0.86      0.85      0.85       360\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8527777777777777"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=10) \n",
    "#random_state는 train데이터와 test 데이터를 분리하는데 적용되는 랜덤성을 결정!\n",
    "#라벨은 0부터 정렬이 되어있기 때문에 feature의 (label/target)이 동일해지기 때문\n",
    "#하지만 random_state의 값을 일치시켜준다면 같은 랜덤성을 받을 수 있다!\n",
    "#즉, 같은 train_data와 test_data를 가질 수 있다 !\n",
    "tree_model.fit(X_train, y_train)\n",
    "#모델 학습!\n",
    "y_pred = tree_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"Accuracy\") \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "macro는 라벨(타겟) 별 각 합의 평균  \n",
    "weighted  avg는 가중 평균으로 개별치에 각각의 중요도, 빈도 등에 따라 가중치를\n",
    "곱해 구해지는 평균"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.97      0.97      0.97        34\n",
      "           4       0.92      0.97      0.95        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       1.00      0.86      0.92        43\n",
      "           9       0.94      0.91      0.92        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9611111111111111"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier(random_state=10)\n",
    "forest_model.fit(X_train, y_train)\n",
    "y_pred = forest_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"Accuracy\") \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.86      0.86      0.86        42\n",
      "           2       1.00      0.97      0.99        40\n",
      "           3       0.92      0.97      0.94        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.93      0.93      0.93        43\n",
      "           9       0.94      0.91      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model = SGDClassifier(random_state = 10)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"Accuracy\") \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = svm.SVC(random_state=10);\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred=svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"Accuracy\") \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       0.97      1.00      0.99        37\n",
      "           5       0.82      0.96      0.89        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.91      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9527777777777777"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state=10)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"Accuracy\") \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다들 쟁쟁하다\n",
    "\n",
    "Decision tree를 제외하고는 모두 소수점 아래 한자리수가 9로 쟁쟁한 성능을 보여줬지만  \n",
    "그 중 근소한 차이로 __SVM__ 이 가장 높은 Accuracy를 보여줬다!  \n",
    "\n",
    "## Accuracy\n",
    "너무 애매했다.. 평가 지표를 선택하는데 있어서 정밀도나 재현율은 이진법 적이라는 생각을 떨칠 수가 없었기 때문이다. 손글씨 분류기는 양성이냐, 음성이냐를 따지는 것이아니라(0이 1이라고 판단하건, 5라고 판단하건 간에 큰 영향이 있다고 생각했기 때문이다)주어진 입력데이터를 정확히 실제 레이블값과 일치 시켜야 한다는 생각이 들었다.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두번째 프로젝트 손글씨 분류기 완료!\n",
    "평가지표 고르는게 정말 고민됐다.. \n",
    "Precision, Recall, F1score, Accuracy 중에서 왠지 Recall과 Precision이 가장 많이 쓰일 것 같다는 생각을 버리지 못해서 한참을 고민하다가 참이냐 거짓이냐의 문제가 아니다 라는 생각이 문뜩 들어서 Accuracy를 선택했는데, 마지막까지도 불안감은 떨칠 수 가 없었다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
